report.enabled = true
workDir = '/scratch/alpine/hdashnow@xsede.org/nextflow_scratch'
// Centralized defaults for params so scripts don't need to set them
params {
    ref  = '/pl/active/dashnowlab/data/ref-genomes/human_GRCh38_no_alt_analysis_set.fasta'
    // Minimum coverage threshold used by filter_meta (can be overridden on the CLI)
    //min_coverage = 35
}
// Helper: pick partition and QoS consistently for a given task
def pickPartitionAndQos = { task ->
    // Be defensive: Nextflow may call these closures without a task (null) during config parsing.
    if (task == null) {
        return [part: 'amilan', qos: 'normal']
    }

    // Safely read memory/time with defaults when properties are missing
    def mem = task.memory ?: 0.GB
    def t = task.time ?: 0.h

    // Partition logic: memory <= 240GB -> 'amilan', else 'amem'
    def part
    if (mem >= 240.GB) {
        part = 'amem'
    } else {
        part = 'amilan'
    }

    def qos
    if (part == 'amem') {
        qos = 'mem'
    } else if (t > 24.h) {
        qos = 'long'
    } else {
        qos = 'normal'
    }
    return [part: part, qos: qos]
}
// Default params you can override on the command line (e.g. --mail_user you@site.edu)

process {
    //scratch = true
    executor = 'slurm'
    // Derive partition (queue) from the shared helper so partition and QoS can't diverge
    queue = { task -> pickPartitionAndQos(task).part }
    // Set some defaults
    time = 8.h //change back to 24?
    
    
    // QoS selection follows the cluster table and is aligned with partition selection
    // Partition is chosen by the same condition as `queue`: memory <= 240.GB -> 'amilan', else 'amem'
    // Use the helper to pick QoS matching the selected partition
    clusterOptions = { task ->
        def qos = pickPartitionAndQos(task).qos
        return "--qos=${qos}"
    }
    maxRetries = 1 // Usually set to 3
    errorStrategy = { task.attempt <= process.maxRetries ? 'retry' : 'finish' }
    resourceLimits = [
        cpus: 48,
        memory: 500.GB,
        time: 72.h
    ]
    withLabel:process_long {
        // Longer default for processes labeled 'process_long'
        params.max_time = 96.h
        time = 168.h
    }
}
executor {
    name = 'slurm'
    queueSize = 1000
    perJobMemLimit = true
    submitRateLimit = '30 / 1 min'
    killBatchSize = 50
}
